{"expireTime":9007200898048143000,"key":"gatsby-plugin-mdx-entire-payload-ceb4220de7e504aa085983a5051e496b-","val":{"mdast":{"type":"root","children":[{"type":"heading","depth":1,"children":[{"type":"text","value":"FAQ","position":{"start":{"line":2,"column":3,"offset":3},"end":{"line":2,"column":6,"offset":6},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":6,"offset":6},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Below you will find answers to the most commonly asked questions regarding Cloudflare Logs. If you cannot find the answer you are looking for, feel free to head over to our ","position":{"start":{"line":4,"column":1,"offset":8},"end":{"line":4,"column":174,"offset":181},"indent":[]}},{"type":"link","title":null,"url":"https://community.cloudflare.com/","children":[{"type":"text","value":"community page","position":{"start":{"line":4,"column":175,"offset":182},"end":{"line":4,"column":189,"offset":196},"indent":[]}}],"position":{"start":{"line":4,"column":174,"offset":181},"end":{"line":4,"column":225,"offset":232},"indent":[]}},{"type":"text","value":" and post your question there.","position":{"start":{"line":4,"column":225,"offset":232},"end":{"line":4,"column":255,"offset":262},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":8},"end":{"line":4,"column":255,"offset":262},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"#general-faq","children":[{"type":"text","value":"General FAQ","position":{"start":{"line":6,"column":4,"offset":267},"end":{"line":6,"column":15,"offset":278},"indent":[]}}],"position":{"start":{"line":6,"column":3,"offset":266},"end":{"line":6,"column":30,"offset":293},"indent":[]}}],"position":{"start":{"line":6,"column":3,"offset":266},"end":{"line":6,"column":30,"offset":293},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":264},"end":{"line":6,"column":30,"offset":293},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"#logpush-faq","children":[{"type":"text","value":"Logpush","position":{"start":{"line":7,"column":4,"offset":297},"end":{"line":7,"column":11,"offset":304},"indent":[]}}],"position":{"start":{"line":7,"column":3,"offset":296},"end":{"line":7,"column":26,"offset":319},"indent":[]}}],"position":{"start":{"line":7,"column":3,"offset":296},"end":{"line":7,"column":26,"offset":319},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":294},"end":{"line":7,"column":26,"offset":319},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"#logpull-api-faq","children":[{"type":"text","value":"Logpull API","position":{"start":{"line":8,"column":4,"offset":323},"end":{"line":8,"column":15,"offset":334},"indent":[]}}],"position":{"start":{"line":8,"column":3,"offset":322},"end":{"line":8,"column":34,"offset":353},"indent":[]}}],"position":{"start":{"line":8,"column":3,"offset":322},"end":{"line":8,"column":34,"offset":353},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":320},"end":{"line":8,"column":34,"offset":353},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":264},"end":{"line":8,"column":34,"offset":353},"indent":[1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"General FAQ","position":{"start":{"line":10,"column":4,"offset":358},"end":{"line":10,"column":15,"offset":369},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":355},"end":{"line":10,"column":15,"offset":369},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Once a request has passed through the Cloudflare network, how soon are the logs available?","position":{"start":{"line":12,"column":5,"offset":375},"end":{"line":12,"column":95,"offset":465},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":371},"end":{"line":12,"column":95,"offset":465},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"When using ","position":{"start":{"line":14,"column":1,"offset":467},"end":{"line":14,"column":12,"offset":478},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Logpush","position":{"start":{"line":14,"column":14,"offset":480},"end":{"line":14,"column":21,"offset":487},"indent":[]}}],"position":{"start":{"line":14,"column":12,"offset":478},"end":{"line":14,"column":23,"offset":489},"indent":[]}},{"type":"text","value":", logs are pushed in batches as soon as possible. For example, if you receive a file at 10:10, the file consists of logs that were processed shortly before 10:10.","position":{"start":{"line":14,"column":23,"offset":489},"end":{"line":14,"column":185,"offset":651},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":467},"end":{"line":14,"column":185,"offset":651},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"When using ","position":{"start":{"line":16,"column":1,"offset":653},"end":{"line":16,"column":12,"offset":664},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Logpull","position":{"start":{"line":16,"column":14,"offset":666},"end":{"line":16,"column":21,"offset":673},"indent":[]}}],"position":{"start":{"line":16,"column":12,"offset":664},"end":{"line":16,"column":23,"offset":675},"indent":[]}},{"type":"text","value":", logs become available in approximately one to five minutes. Cloudflare requires that calls to the ","position":{"start":{"line":16,"column":23,"offset":675},"end":{"line":16,"column":123,"offset":775},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Logpull API","position":{"start":{"line":16,"column":125,"offset":777},"end":{"line":16,"column":136,"offset":788},"indent":[]}}],"position":{"start":{"line":16,"column":123,"offset":775},"end":{"line":16,"column":138,"offset":790},"indent":[]}},{"type":"text","value":" to be for time periods of at least one minute in the past. For example, if it is 9:43 now, you can ask for logs processed between 9:41 and 9:42. The response will include logs for requests that passed through our network between 9:41 and 9:42 and potentially earlier. It is normal for our processing to take between three and four minutes, so when you ask for that same time period, you may also see logs of requests that passed through our network at 9:39 or earlier.","position":{"start":{"line":16,"column":138,"offset":790},"end":{"line":16,"column":607,"offset":1259},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":653},"end":{"line":16,"column":607,"offset":1259},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"These timings are only a guideline, not a guarantee, and may depend on network conditions, the request volume for your domain, and other factors. Although we try to get the logs to you as fast as possible, we prioritize not losing log data over speed. On rare occasions, you may see a longer delay. In this case, you do not need to take any action. The logs will be available as soon as they are processed.","position":{"start":{"line":18,"column":1,"offset":1261},"end":{"line":18,"column":407,"offset":1667},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":1261},"end":{"line":18,"column":407,"offset":1667},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Are logs available for customers who are not on an Enterprise plan?","position":{"start":{"line":20,"column":5,"offset":1673},"end":{"line":20,"column":72,"offset":1740},"indent":[]}}],"position":{"start":{"line":20,"column":1,"offset":1669},"end":{"line":20,"column":72,"offset":1740},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Not yet, but we are planning to make them available to other customer plans in the future.","position":{"start":{"line":22,"column":1,"offset":1742},"end":{"line":22,"column":91,"offset":1832},"indent":[]}}],"position":{"start":{"line":22,"column":1,"offset":1742},"end":{"line":22,"column":91,"offset":1832},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"When pulling or pushing logs, I occasionally come across a time period with no data, even though I am sure my domain received requests at that time. Is this an expected behavior?","position":{"start":{"line":24,"column":5,"offset":1838},"end":{"line":24,"column":183,"offset":2016},"indent":[]}}],"position":{"start":{"line":24,"column":1,"offset":1834},"end":{"line":24,"column":183,"offset":2016},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Yes. The time period for which you pull or receive logs is based on our processing time, not the time the requests passed through our network. Empty responses do not mean there were no requests during that time period, just that we did not process any logs for your domain during that time.","position":{"start":{"line":26,"column":1,"offset":2018},"end":{"line":26,"column":291,"offset":2308},"indent":[]}}],"position":{"start":{"line":26,"column":1,"offset":2018},"end":{"line":26,"column":291,"offset":2308},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Can I receive logs in a format other than JSON?","position":{"start":{"line":28,"column":5,"offset":2314},"end":{"line":28,"column":52,"offset":2361},"indent":[]}}],"position":{"start":{"line":28,"column":1,"offset":2310},"end":{"line":28,"column":52,"offset":2361},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Not at this time. Talk to your account manager or Cloudflare Support if you are interested in other formats and we will consider them for the future.","position":{"start":{"line":30,"column":1,"offset":2363},"end":{"line":30,"column":150,"offset":2512},"indent":[]}}],"position":{"start":{"line":30,"column":1,"offset":2363},"end":{"line":30,"column":150,"offset":2512},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Logpush FAQ","position":{"start":{"line":32,"column":4,"offset":2517},"end":{"line":32,"column":15,"offset":2528},"indent":[]}}],"position":{"start":{"line":32,"column":1,"offset":2514},"end":{"line":32,"column":15,"offset":2528},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"What happens if my cloud storage destination is temporarily unavailable?","position":{"start":{"line":34,"column":5,"offset":2534},"end":{"line":34,"column":77,"offset":2606},"indent":[]}}],"position":{"start":{"line":34,"column":1,"offset":2530},"end":{"line":34,"column":77,"offset":2606},"indent":[]}},{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Logpush","position":{"start":{"line":36,"column":3,"offset":2610},"end":{"line":36,"column":10,"offset":2617},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":2608},"end":{"line":36,"column":12,"offset":2619},"indent":[]}},{"type":"text","value":" is designed to retry in case of errors. If your destination is temporarily unavailable, Logpush will make the best effort to retry. If Cloudflare persistently receives errors from your destination, Logpush will eventually drop logs. If the errors continue for a prolonged period of time, Logpush will assume that the destination is permanently unavailable and disable your push job. You can always re-enable the job later.","position":{"start":{"line":36,"column":12,"offset":2619},"end":{"line":36,"column":435,"offset":3042},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":2608},"end":{"line":36,"column":435,"offset":3042},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Can I adjust how often logs are pushed?","position":{"start":{"line":38,"column":5,"offset":3048},"end":{"line":38,"column":44,"offset":3087},"indent":[]}}],"position":{"start":{"line":38,"column":1,"offset":3044},"end":{"line":38,"column":44,"offset":3087},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"No. Cloudflare pushes logs in batches as soon as possible.","position":{"start":{"line":40,"column":1,"offset":3089},"end":{"line":40,"column":59,"offset":3147},"indent":[]}}],"position":{"start":{"line":40,"column":1,"offset":3089},"end":{"line":40,"column":59,"offset":3147},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"My job was accidentally turned off, and I did not receive my logs for a certain time period. Can they still be pushed to me?","position":{"start":{"line":42,"column":5,"offset":3153},"end":{"line":42,"column":129,"offset":3277},"indent":[]}}],"position":{"start":{"line":42,"column":1,"offset":3149},"end":{"line":42,"column":129,"offset":3277},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"No. ","position":{"start":{"line":44,"column":1,"offset":3279},"end":{"line":44,"column":5,"offset":3283},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Logpush","position":{"start":{"line":44,"column":7,"offset":3285},"end":{"line":44,"column":14,"offset":3292},"indent":[]}}],"position":{"start":{"line":44,"column":5,"offset":3283},"end":{"line":44,"column":16,"offset":3294},"indent":[]}},{"type":"text","value":" only pushes the logs once as they become available and is unable to backfill. However, the logs are stored for at least 72 hours and can be downloaded using the ","position":{"start":{"line":44,"column":16,"offset":3294},"end":{"line":44,"column":178,"offset":3456},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Logpull API","position":{"start":{"line":44,"column":180,"offset":3458},"end":{"line":44,"column":191,"offset":3469},"indent":[]}}],"position":{"start":{"line":44,"column":178,"offset":3456},"end":{"line":44,"column":193,"offset":3471},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":44,"column":193,"offset":3471},"end":{"line":44,"column":194,"offset":3472},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":3279},"end":{"line":44,"column":194,"offset":3472},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why am I receiving a validating destination error while setting up a Splunk job?","position":{"start":{"line":46,"column":5,"offset":3478},"end":{"line":46,"column":85,"offset":3558},"indent":[]}}],"position":{"start":{"line":46,"column":1,"offset":3474},"end":{"line":46,"column":86,"offset":3559},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"You could be seeing this error for multiple reasons:","position":{"start":{"line":47,"column":1,"offset":3560},"end":{"line":47,"column":53,"offset":3612},"indent":[]}}],"position":{"start":{"line":47,"column":1,"offset":3560},"end":{"line":47,"column":53,"offset":3612},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"The Splunk endpoint URL is not correct. Cloudflare only supports Splunk HEC raw endpoint over HTTPS.","position":{"start":{"line":48,"column":3,"offset":3615},"end":{"line":48,"column":103,"offset":3715},"indent":[]}}],"position":{"start":{"line":48,"column":3,"offset":3615},"end":{"line":48,"column":103,"offset":3715},"indent":[]}}],"position":{"start":{"line":48,"column":1,"offset":3613},"end":{"line":48,"column":103,"offset":3715},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"The Splunk authentication token is not correct. Be sure to URL-encode the token. For example, use ","position":{"start":{"line":49,"column":3,"offset":3718},"end":{"line":49,"column":101,"offset":3816},"indent":[]}},{"type":"inlineCode","value":"%20","position":{"start":{"line":49,"column":101,"offset":3816},"end":{"line":49,"column":106,"offset":3821},"indent":[]}},{"type":"text","value":" for a space.","position":{"start":{"line":49,"column":106,"offset":3821},"end":{"line":49,"column":119,"offset":3834},"indent":[]}}],"position":{"start":{"line":49,"column":3,"offset":3718},"end":{"line":49,"column":119,"offset":3834},"indent":[]}}],"position":{"start":{"line":49,"column":1,"offset":3716},"end":{"line":49,"column":119,"offset":3834},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"The certificate for Splunk Server is not properly configured. Certificates generated by Splunk/third-party certificates should have the ","position":{"start":{"line":50,"column":3,"offset":3837},"end":{"line":50,"column":139,"offset":3973},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Common Name","position":{"start":{"line":50,"column":141,"offset":3975},"end":{"line":50,"column":152,"offset":3986},"indent":[]}}],"position":{"start":{"line":50,"column":139,"offset":3973},"end":{"line":50,"column":154,"offset":3988},"indent":[]}},{"type":"text","value":" field in the certificate match the Splunk server’s domain name. Otherwise you may see errors like: ","position":{"start":{"line":50,"column":154,"offset":3988},"end":{"line":50,"column":254,"offset":4088},"indent":[]}},{"type":"inlineCode","value":"x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.","position":{"start":{"line":50,"column":254,"offset":4088},"end":{"line":50,"column":348,"offset":4182},"indent":[]}}],"position":{"start":{"line":50,"column":3,"offset":3837},"end":{"line":50,"column":348,"offset":4182},"indent":[]}}],"position":{"start":{"line":50,"column":1,"offset":3835},"end":{"line":50,"column":348,"offset":4182},"indent":[]}}],"position":{"start":{"line":48,"column":1,"offset":3613},"end":{"line":50,"column":348,"offset":4182},"indent":[1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"What is the insecure-skip-verify parameter in Splunk jobs?","position":{"start":{"line":52,"column":5,"offset":4188},"end":{"line":52,"column":63,"offset":4246},"indent":[]}}],"position":{"start":{"line":52,"column":1,"offset":4184},"end":{"line":52,"column":63,"offset":4246},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"This flag, if set to ","position":{"start":{"line":53,"column":1,"offset":4247},"end":{"line":53,"column":22,"offset":4268},"indent":[]}},{"type":"inlineCode","value":"true","position":{"start":{"line":53,"column":22,"offset":4268},"end":{"line":53,"column":28,"offset":4274},"indent":[]}},{"type":"text","value":", makes an insecure connection to Splunk. Setting this value to ","position":{"start":{"line":53,"column":28,"offset":4274},"end":{"line":53,"column":92,"offset":4338},"indent":[]}},{"type":"inlineCode","value":"true","position":{"start":{"line":53,"column":92,"offset":4338},"end":{"line":53,"column":98,"offset":4344},"indent":[]}},{"type":"text","value":" is equivalent to using the ","position":{"start":{"line":53,"column":98,"offset":4344},"end":{"line":53,"column":126,"offset":4372},"indent":[]}},{"type":"inlineCode","value":"-k","position":{"start":{"line":53,"column":126,"offset":4372},"end":{"line":53,"column":130,"offset":4376},"indent":[]}},{"type":"text","value":" option with ","position":{"start":{"line":53,"column":130,"offset":4376},"end":{"line":53,"column":143,"offset":4389},"indent":[]}},{"type":"inlineCode","value":"curl","position":{"start":{"line":53,"column":143,"offset":4389},"end":{"line":53,"column":149,"offset":4395},"indent":[]}},{"type":"text","value":" as shown in Splunk examples and is ","position":{"start":{"line":53,"column":149,"offset":4395},"end":{"line":53,"column":185,"offset":4431},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"not","position":{"start":{"line":53,"column":187,"offset":4433},"end":{"line":53,"column":190,"offset":4436},"indent":[]}}],"position":{"start":{"line":53,"column":185,"offset":4431},"end":{"line":53,"column":192,"offset":4438},"indent":[]}},{"type":"text","value":" recommended. Cloudflare highly recommends setting this flag to ","position":{"start":{"line":53,"column":192,"offset":4438},"end":{"line":53,"column":256,"offset":4502},"indent":[]}},{"type":"inlineCode","value":"false","position":{"start":{"line":53,"column":256,"offset":4502},"end":{"line":53,"column":263,"offset":4509},"indent":[]}},{"type":"text","value":" when using the ","position":{"start":{"line":53,"column":263,"offset":4509},"end":{"line":53,"column":279,"offset":4525},"indent":[]}},{"type":"inlineCode","value":"insecure-skip-verify","position":{"start":{"line":53,"column":279,"offset":4525},"end":{"line":53,"column":301,"offset":4547},"indent":[]}},{"type":"text","value":" parameter.","position":{"start":{"line":53,"column":301,"offset":4547},"end":{"line":53,"column":312,"offset":4558},"indent":[]}}],"position":{"start":{"line":53,"column":1,"offset":4247},"end":{"line":53,"column":312,"offset":4558},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why do we have the insecure-skip-verify parameter in Splunk jobs, if it is not recommended?","position":{"start":{"line":55,"column":5,"offset":4564},"end":{"line":55,"column":96,"offset":4655},"indent":[]}}],"position":{"start":{"line":55,"column":1,"offset":4560},"end":{"line":55,"column":96,"offset":4655},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Certificates generated by Splunk/third-party certificates should have the ","position":{"start":{"line":56,"column":1,"offset":4656},"end":{"line":56,"column":75,"offset":4730},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Common Name","position":{"start":{"line":56,"column":77,"offset":4732},"end":{"line":56,"column":88,"offset":4743},"indent":[]}}],"position":{"start":{"line":56,"column":75,"offset":4730},"end":{"line":56,"column":90,"offset":4745},"indent":[]}},{"type":"text","value":" field in the certificate match the Splunk server’s domain name. Otherwise you may see errors like: ","position":{"start":{"line":56,"column":90,"offset":4745},"end":{"line":56,"column":190,"offset":4845},"indent":[]}},{"type":"inlineCode","value":"x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.","position":{"start":{"line":56,"column":190,"offset":4845},"end":{"line":56,"column":284,"offset":4939},"indent":[]}},{"type":"text","value":" This happens especially with the default certificates generated by Splunk on startup. Pushes will never succeed unless the certificates are fixed.","position":{"start":{"line":56,"column":284,"offset":4939},"end":{"line":56,"column":431,"offset":5086},"indent":[]}}],"position":{"start":{"line":56,"column":1,"offset":4656},"end":{"line":56,"column":431,"offset":5086},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The proper way to resolve the issue is to fix the certificates. This flag is only here for those rare scenarios when it is not possible to have access or permissions to fix the certificates, like with the Splunk cloud instances, which do not allow changing Splunk server configurations.","position":{"start":{"line":58,"column":1,"offset":5088},"end":{"line":58,"column":287,"offset":5374},"indent":[]}}],"position":{"start":{"line":58,"column":1,"offset":5088},"end":{"line":58,"column":287,"offset":5374},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"How can I verify that my Splunk HEC is working correctly before setting up a job?","position":{"start":{"line":60,"column":5,"offset":5380},"end":{"line":60,"column":86,"offset":5461},"indent":[]}}],"position":{"start":{"line":60,"column":1,"offset":5376},"end":{"line":60,"column":86,"offset":5461},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Ensure that you can publish events to your Splunk instance through ","position":{"start":{"line":61,"column":1,"offset":5462},"end":{"line":61,"column":68,"offset":5529},"indent":[]}},{"type":"inlineCode","value":"curl","position":{"start":{"line":61,"column":68,"offset":5529},"end":{"line":61,"column":74,"offset":5535},"indent":[]}},{"type":"text","value":" without the ","position":{"start":{"line":61,"column":74,"offset":5535},"end":{"line":61,"column":87,"offset":5548},"indent":[]}},{"type":"inlineCode","value":"-k","position":{"start":{"line":61,"column":87,"offset":5548},"end":{"line":61,"column":91,"offset":5552},"indent":[]}},{"type":"text","value":" flag and with the ","position":{"start":{"line":61,"column":91,"offset":5552},"end":{"line":61,"column":110,"offset":5571},"indent":[]}},{"type":"inlineCode","value":"insecure-skip-verify","position":{"start":{"line":61,"column":110,"offset":5571},"end":{"line":61,"column":132,"offset":5593},"indent":[]}},{"type":"text","value":" parameter set to ","position":{"start":{"line":61,"column":132,"offset":5593},"end":{"line":61,"column":150,"offset":5611},"indent":[]}},{"type":"inlineCode","value":"false","position":{"start":{"line":61,"column":150,"offset":5611},"end":{"line":61,"column":157,"offset":5618},"indent":[]}},{"type":"text","value":", as in the following example:","position":{"start":{"line":61,"column":157,"offset":5618},"end":{"line":61,"column":187,"offset":5648},"indent":[]}}],"position":{"start":{"line":61,"column":1,"offset":5462},"end":{"line":61,"column":187,"offset":5648},"indent":[]}},{"type":"code","lang":"bash","meta":null,"value":"curl  \"https://<SPLUNK_ENDPOINT_URL>?channel=<SPLUNK_CHANNEL_ID>&insecure-skip-verify=<INSECURE_SKIP_VERIFY>&sourcetype=<SOURCE_TYPE>\" \\\n   -H \"Authorization: Splunk <SPLUNK_AUTH_TOKEN>\" \\\n   -d '{\"BotScore\":99,\"BotScoreSrc\":\"Machine Learning\",\"CacheCacheStatus\":\"miss\",\"CacheResponseBytes\":2478}'\n{\"text\":\"Success\",\"code\":0}","position":{"start":{"line":63,"column":1,"offset":5650},"end":{"line":68,"column":4,"offset":5987},"indent":[1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Can I use any HEC network port in the Splunk destination conf?","position":{"start":{"line":70,"column":5,"offset":5993},"end":{"line":70,"column":67,"offset":6055},"indent":[]}}],"position":{"start":{"line":70,"column":1,"offset":5989},"end":{"line":70,"column":67,"offset":6055},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"No. Cloudflare expects the HEC network port to be configured to ","position":{"start":{"line":71,"column":1,"offset":6056},"end":{"line":71,"column":65,"offset":6120},"indent":[]}},{"type":"inlineCode","value":":443","position":{"start":{"line":71,"column":65,"offset":6120},"end":{"line":71,"column":71,"offset":6126},"indent":[]}},{"type":"text","value":" or ","position":{"start":{"line":71,"column":71,"offset":6126},"end":{"line":71,"column":75,"offset":6130},"indent":[]}},{"type":"inlineCode","value":":8088","position":{"start":{"line":71,"column":75,"offset":6130},"end":{"line":71,"column":82,"offset":6137},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":71,"column":82,"offset":6137},"end":{"line":71,"column":83,"offset":6138},"indent":[]}}],"position":{"start":{"line":71,"column":1,"offset":6056},"end":{"line":71,"column":83,"offset":6138},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Does Logpush integrate with the Cloudflare Splunk App?","position":{"start":{"line":73,"column":5,"offset":6144},"end":{"line":73,"column":59,"offset":6198},"indent":[]}}],"position":{"start":{"line":73,"column":1,"offset":6140},"end":{"line":73,"column":59,"offset":6198},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Yes. See ","position":{"start":{"line":74,"column":1,"offset":6199},"end":{"line":74,"column":10,"offset":6208},"indent":[]}},{"type":"link","title":null,"url":"https://splunkbase.splunk.com/app/4501/","children":[{"type":"text","value":"Cloudflare App for Splunk","position":{"start":{"line":74,"column":11,"offset":6209},"end":{"line":74,"column":36,"offset":6234},"indent":[]}}],"position":{"start":{"line":74,"column":10,"offset":6208},"end":{"line":74,"column":78,"offset":6276},"indent":[]}},{"type":"text","value":" for more information. As long as you ingest logs using the ","position":{"start":{"line":74,"column":78,"offset":6276},"end":{"line":74,"column":138,"offset":6336},"indent":[]}},{"type":"inlineCode","value":"cloudflare:json","position":{"start":{"line":74,"column":138,"offset":6336},"end":{"line":74,"column":155,"offset":6353},"indent":[]}},{"type":"text","value":" source type, you can use the Cloudflare Splunk App.","position":{"start":{"line":74,"column":155,"offset":6353},"end":{"line":74,"column":207,"offset":6405},"indent":[]}}],"position":{"start":{"line":74,"column":1,"offset":6199},"end":{"line":74,"column":207,"offset":6405},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Logpull API FAQ","position":{"start":{"line":76,"column":4,"offset":6410},"end":{"line":76,"column":19,"offset":6425},"indent":[]}}],"position":{"start":{"line":76,"column":1,"offset":6407},"end":{"line":76,"column":19,"offset":6425},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"How long are logs retained?","position":{"start":{"line":78,"column":5,"offset":6431},"end":{"line":78,"column":32,"offset":6458},"indent":[]}}],"position":{"start":{"line":78,"column":1,"offset":6427},"end":{"line":78,"column":32,"offset":6458},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Cloudflare makes logs available for at least three days and up to seven days. If you need your logs for a longer time period, download and store them locally.","position":{"start":{"line":80,"column":1,"offset":6460},"end":{"line":80,"column":159,"offset":6618},"indent":[]}}],"position":{"start":{"line":80,"column":1,"offset":6460},"end":{"line":80,"column":159,"offset":6618},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"I am asking for logs for the time window of 16:10-16:13. However, the timestamps in the logs show requests that are before this time period. Why does that happen?","position":{"start":{"line":82,"column":5,"offset":6624},"end":{"line":82,"column":167,"offset":6786},"indent":[]}}],"position":{"start":{"line":82,"column":1,"offset":6620},"end":{"line":82,"column":167,"offset":6786},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"When you make a call for the time period of 16:10-16:13, you are actually asking for the logs that were received and processed by our system during that time (hence the endpoint name, ","position":{"start":{"line":84,"column":1,"offset":6788},"end":{"line":84,"column":185,"offset":6972},"indent":[]}},{"type":"inlineCode","value":"logs/received","position":{"start":{"line":84,"column":185,"offset":6972},"end":{"line":84,"column":200,"offset":6987},"indent":[]}},{"type":"text","value":"). The received time is the time the logs are written to disk. There is some delay between the time the request hits the Cloudflare edge and the time it is received and processed. The ","position":{"start":{"line":84,"column":200,"offset":6987},"end":{"line":84,"column":384,"offset":7171},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"request time","position":{"start":{"line":84,"column":386,"offset":7173},"end":{"line":84,"column":398,"offset":7185},"indent":[]}}],"position":{"start":{"line":84,"column":384,"offset":7171},"end":{"line":84,"column":400,"offset":7187},"indent":[]}},{"type":"text","value":" is what you see in the log itself: ","position":{"start":{"line":84,"column":400,"offset":7187},"end":{"line":84,"column":436,"offset":7223},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"EdgeStartTimestamp","position":{"start":{"line":84,"column":438,"offset":7225},"end":{"line":84,"column":456,"offset":7243},"indent":[]}}],"position":{"start":{"line":84,"column":436,"offset":7223},"end":{"line":84,"column":458,"offset":7245},"indent":[]}},{"type":"text","value":" and ","position":{"start":{"line":84,"column":458,"offset":7245},"end":{"line":84,"column":463,"offset":7250},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"EdgeEndTimestamp","position":{"start":{"line":84,"column":465,"offset":7252},"end":{"line":84,"column":481,"offset":7268},"indent":[]}}],"position":{"start":{"line":84,"column":463,"offset":7250},"end":{"line":84,"column":483,"offset":7270},"indent":[]}},{"type":"text","value":" tell you when the edge started and stopped processing the request.","position":{"start":{"line":84,"column":483,"offset":7270},"end":{"line":84,"column":550,"offset":7337},"indent":[]}}],"position":{"start":{"line":84,"column":1,"offset":6788},"end":{"line":84,"column":550,"offset":7337},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The advantage of basing the responses on the ","position":{"start":{"line":86,"column":1,"offset":7339},"end":{"line":86,"column":46,"offset":7384},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"time received","position":{"start":{"line":86,"column":48,"offset":7386},"end":{"line":86,"column":61,"offset":7399},"indent":[]}}],"position":{"start":{"line":86,"column":46,"offset":7384},"end":{"line":86,"column":63,"offset":7401},"indent":[]}},{"type":"text","value":" rather than the request or edge time is not needing to worry about late-arriving logs. As long as you are calling our API for continuous time segments, you will always get all of your logs without making duplicate calls. If we based the response on request time, you could never be sure that all the logs for that request time had been processed.","position":{"start":{"line":86,"column":63,"offset":7401},"end":{"line":86,"column":410,"offset":7748},"indent":[]}}],"position":{"start":{"line":86,"column":1,"offset":7339},"end":{"line":86,"column":410,"offset":7748},"indent":[]}},{"type":"export","value":"export const _frontmatter = {\"order\":130,\"pcx-content-type\":\"faq\"}","position":{"start":{"line":89,"column":1,"offset":7751},"end":{"line":89,"column":67,"offset":7817},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":89,"column":67,"offset":7817}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"order\": 130,\n  \"pcx-content-type\": \"faq\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"faq\"\n  }, \"FAQ\"), mdx(\"p\", null, \"Below you will find answers to the most commonly asked questions regarding Cloudflare Logs. If you cannot find the answer you are looking for, feel free to head over to our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://community.cloudflare.com/\"\n  }, \"community page\"), \" and post your question there.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#general-faq\"\n  }, \"General FAQ\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#logpush-faq\"\n  }, \"Logpush\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#logpull-api-faq\"\n  }, \"Logpull API\"))), mdx(\"h2\", {\n    \"id\": \"general-faq\"\n  }, \"General FAQ\"), mdx(\"h3\", {\n    \"id\": \"once-a-request-has-passed-through-the-cloudflare-network-how-soon-are-the-logs-available\"\n  }, \"Once a request has passed through the Cloudflare network, how soon are the logs available?\"), mdx(\"p\", null, \"When using \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpush\"), \", logs are pushed in batches as soon as possible. For example, if you receive a file at 10:10, the file consists of logs that were processed shortly before 10:10.\"), mdx(\"p\", null, \"When using \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpull\"), \", logs become available in approximately one to five minutes. Cloudflare requires that calls to the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpull API\"), \" to be for time periods of at least one minute in the past. For example, if it is 9:43 now, you can ask for logs processed between 9:41 and 9:42. The response will include logs for requests that passed through our network between 9:41 and 9:42 and potentially earlier. It is normal for our processing to take between three and four minutes, so when you ask for that same time period, you may also see logs of requests that passed through our network at 9:39 or earlier.\"), mdx(\"p\", null, \"These timings are only a guideline, not a guarantee, and may depend on network conditions, the request volume for your domain, and other factors. Although we try to get the logs to you as fast as possible, we prioritize not losing log data over speed. On rare occasions, you may see a longer delay. In this case, you do not need to take any action. The logs will be available as soon as they are processed.\"), mdx(\"h3\", {\n    \"id\": \"are-logs-available-for-customers-who-are-not-on-an-enterprise-plan\"\n  }, \"Are logs available for customers who are not on an Enterprise plan?\"), mdx(\"p\", null, \"Not yet, but we are planning to make them available to other customer plans in the future.\"), mdx(\"h3\", {\n    \"id\": \"when-pulling-or-pushing-logs-i-occasionally-come-across-a-time-period-with-no-data-even-though-i-am-sure-my-domain-received-requests-at-that-time-is-this-an-expected-behavior\"\n  }, \"When pulling or pushing logs, I occasionally come across a time period with no data, even though I am sure my domain received requests at that time. Is this an expected behavior?\"), mdx(\"p\", null, \"Yes. The time period for which you pull or receive logs is based on our processing time, not the time the requests passed through our network. Empty responses do not mean there were no requests during that time period, just that we did not process any logs for your domain during that time.\"), mdx(\"h3\", {\n    \"id\": \"can-i-receive-logs-in-a-format-other-than-json\"\n  }, \"Can I receive logs in a format other than JSON?\"), mdx(\"p\", null, \"Not at this time. Talk to your account manager or Cloudflare Support if you are interested in other formats and we will consider them for the future.\"), mdx(\"h2\", {\n    \"id\": \"logpush-faq\"\n  }, \"Logpush FAQ\"), mdx(\"h3\", {\n    \"id\": \"what-happens-if-my-cloud-storage-destination-is-temporarily-unavailable\"\n  }, \"What happens if my cloud storage destination is temporarily unavailable?\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpush\"), \" is designed to retry in case of errors. If your destination is temporarily unavailable, Logpush will make the best effort to retry. If Cloudflare persistently receives errors from your destination, Logpush will eventually drop logs. If the errors continue for a prolonged period of time, Logpush will assume that the destination is permanently unavailable and disable your push job. You can always re-enable the job later.\"), mdx(\"h3\", {\n    \"id\": \"can-i-adjust-how-often-logs-are-pushed\"\n  }, \"Can I adjust how often logs are pushed?\"), mdx(\"p\", null, \"No. Cloudflare pushes logs in batches as soon as possible.\"), mdx(\"h3\", {\n    \"id\": \"my-job-was-accidentally-turned-off-and-i-did-not-receive-my-logs-for-a-certain-time-period-can-they-still-be-pushed-to-me\"\n  }, \"My job was accidentally turned off, and I did not receive my logs for a certain time period. Can they still be pushed to me?\"), mdx(\"p\", null, \"No. \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpush\"), \" only pushes the logs once as they become available and is unable to backfill. However, the logs are stored for at least 72 hours and can be downloaded using the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Logpull API\"), \".\"), mdx(\"h3\", {\n    \"id\": \"why-am-i-receiving-a-validating-destination-error-while-setting-up-a-splunk-job\"\n  }, \"Why am I receiving a validating destination error while setting up a Splunk job?\"), mdx(\"p\", null, \"You could be seeing this error for multiple reasons:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The Splunk endpoint URL is not correct. Cloudflare only supports Splunk HEC raw endpoint over HTTPS.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The Splunk authentication token is not correct. Be sure to URL-encode the token. For example, use \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"%20\"), \" for a space.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The certificate for Splunk Server is not properly configured. Certificates generated by Splunk/third-party certificates should have the \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Common Name\"), \" field in the certificate match the Splunk server\\u2019s domain name. Otherwise you may see errors like: \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.\"))), mdx(\"h3\", {\n    \"id\": \"what-is-the-insecure-skip-verify-parameter-in-splunk-jobs\"\n  }, \"What is the insecure-skip-verify parameter in Splunk jobs?\"), mdx(\"p\", null, \"This flag, if set to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"true\"), \", makes an insecure connection to Splunk. Setting this value to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"true\"), \" is equivalent to using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"-k\"), \" option with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"curl\"), \" as shown in Splunk examples and is \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"not\"), \" recommended. Cloudflare highly recommends setting this flag to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"false\"), \" when using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"insecure-skip-verify\"), \" parameter.\"), mdx(\"h3\", {\n    \"id\": \"why-do-we-have-the-insecure-skip-verify-parameter-in-splunk-jobs-if-it-is-not-recommended\"\n  }, \"Why do we have the insecure-skip-verify parameter in Splunk jobs, if it is not recommended?\"), mdx(\"p\", null, \"Certificates generated by Splunk/third-party certificates should have the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Common Name\"), \" field in the certificate match the Splunk server\\u2019s domain name. Otherwise you may see errors like: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.\"), \" This happens especially with the default certificates generated by Splunk on startup. Pushes will never succeed unless the certificates are fixed.\"), mdx(\"p\", null, \"The proper way to resolve the issue is to fix the certificates. This flag is only here for those rare scenarios when it is not possible to have access or permissions to fix the certificates, like with the Splunk cloud instances, which do not allow changing Splunk server configurations.\"), mdx(\"h3\", {\n    \"id\": \"how-can-i-verify-that-my-splunk-hec-is-working-correctly-before-setting-up-a-job\"\n  }, \"How can I verify that my Splunk HEC is working correctly before setting up a job?\"), mdx(\"p\", null, \"Ensure that you can publish events to your Splunk instance through \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"curl\"), \" without the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"-k\"), \" flag and with the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"insecure-skip-verify\"), \" parameter set to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"false\"), \", as in the following example:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"curl  \\\"https://<SPLUNK_ENDPOINT_URL>?channel=<SPLUNK_CHANNEL_ID>&insecure-skip-verify=<INSECURE_SKIP_VERIFY>&sourcetype=<SOURCE_TYPE>\\\" \\\\\\n   -H \\\"Authorization: Splunk <SPLUNK_AUTH_TOKEN>\\\" \\\\\\n   -d '{\\\"BotScore\\\":99,\\\"BotScoreSrc\\\":\\\"Machine Learning\\\",\\\"CacheCacheStatus\\\":\\\"miss\\\",\\\"CacheResponseBytes\\\":2478}'\\n{\\\"text\\\":\\\"Success\\\",\\\"code\\\":0}\\n\")), mdx(\"h3\", {\n    \"id\": \"can-i-use-any-hec-network-port-in-the-splunk-destination-conf\"\n  }, \"Can I use any HEC network port in the Splunk destination conf?\"), mdx(\"p\", null, \"No. Cloudflare expects the HEC network port to be configured to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \":443\"), \" or \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \":8088\"), \".\"), mdx(\"h3\", {\n    \"id\": \"does-logpush-integrate-with-the-cloudflare-splunk-app\"\n  }, \"Does Logpush integrate with the Cloudflare Splunk App?\"), mdx(\"p\", null, \"Yes. See \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://splunkbase.splunk.com/app/4501/\"\n  }, \"Cloudflare App for Splunk\"), \" for more information. As long as you ingest logs using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cloudflare:json\"), \" source type, you can use the Cloudflare Splunk App.\"), mdx(\"h2\", {\n    \"id\": \"logpull-api-faq\"\n  }, \"Logpull API FAQ\"), mdx(\"h3\", {\n    \"id\": \"how-long-are-logs-retained\"\n  }, \"How long are logs retained?\"), mdx(\"p\", null, \"Cloudflare makes logs available for at least three days and up to seven days. If you need your logs for a longer time period, download and store them locally.\"), mdx(\"h3\", {\n    \"id\": \"i-am-asking-for-logs-for-the-time-window-of-1610-1613-however-the-timestamps-in-the-logs-show-requests-that-are-before-this-time-period-why-does-that-happen\"\n  }, \"I am asking for logs for the time window of 16:10-16:13. However, the timestamps in the logs show requests that are before this time period. Why does that happen?\"), mdx(\"p\", null, \"When you make a call for the time period of 16:10-16:13, you are actually asking for the logs that were received and processed by our system during that time (hence the endpoint name, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"logs/received\"), \"). The received time is the time the logs are written to disk. There is some delay between the time the request hits the Cloudflare edge and the time it is received and processed. The \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"request time\"), \" is what you see in the log itself: \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EdgeStartTimestamp\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EdgeEndTimestamp\"), \" tell you when the edge started and stopped processing the request.\"), mdx(\"p\", null, \"The advantage of basing the responses on the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"time received\"), \" rather than the request or edge time is not needing to worry about late-arriving logs. As long as you are calling our API for continuous time segments, you will always get all of your logs without making duplicate calls. If we based the response on request time, you could never be sure that all the logs for that request time had been processed.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"order\": 130,\n  \"pcx-content-type\": \"faq\"\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h1 {...{\n      \"id\": \"faq\"\n    }}>{`FAQ`}</h1>\n    <p>{`Below you will find answers to the most commonly asked questions regarding Cloudflare Logs. If you cannot find the answer you are looking for, feel free to head over to our `}<a parentName=\"p\" {...{\n        \"href\": \"https://community.cloudflare.com/\"\n      }}>{`community page`}</a>{` and post your question there.`}</p>\n    <ul>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"#general-faq\"\n        }}>{`General FAQ`}</a></li>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"#logpush-faq\"\n        }}>{`Logpush`}</a></li>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"#logpull-api-faq\"\n        }}>{`Logpull API`}</a></li>\n    </ul>\n    <h2 {...{\n      \"id\": \"general-faq\"\n    }}>{`General FAQ`}</h2>\n    <h3 {...{\n      \"id\": \"once-a-request-has-passed-through-the-cloudflare-network-how-soon-are-the-logs-available\"\n    }}>{`Once a request has passed through the Cloudflare network, how soon are the logs available?`}</h3>\n    <p>{`When using `}<strong parentName=\"p\">{`Logpush`}</strong>{`, logs are pushed in batches as soon as possible. For example, if you receive a file at 10:10, the file consists of logs that were processed shortly before 10:10.`}</p>\n    <p>{`When using `}<strong parentName=\"p\">{`Logpull`}</strong>{`, logs become available in approximately one to five minutes. Cloudflare requires that calls to the `}<strong parentName=\"p\">{`Logpull API`}</strong>{` to be for time periods of at least one minute in the past. For example, if it is 9:43 now, you can ask for logs processed between 9:41 and 9:42. The response will include logs for requests that passed through our network between 9:41 and 9:42 and potentially earlier. It is normal for our processing to take between three and four minutes, so when you ask for that same time period, you may also see logs of requests that passed through our network at 9:39 or earlier.`}</p>\n    <p>{`These timings are only a guideline, not a guarantee, and may depend on network conditions, the request volume for your domain, and other factors. Although we try to get the logs to you as fast as possible, we prioritize not losing log data over speed. On rare occasions, you may see a longer delay. In this case, you do not need to take any action. The logs will be available as soon as they are processed.`}</p>\n    <h3 {...{\n      \"id\": \"are-logs-available-for-customers-who-are-not-on-an-enterprise-plan\"\n    }}>{`Are logs available for customers who are not on an Enterprise plan?`}</h3>\n    <p>{`Not yet, but we are planning to make them available to other customer plans in the future.`}</p>\n    <h3 {...{\n      \"id\": \"when-pulling-or-pushing-logs-i-occasionally-come-across-a-time-period-with-no-data-even-though-i-am-sure-my-domain-received-requests-at-that-time-is-this-an-expected-behavior\"\n    }}>{`When pulling or pushing logs, I occasionally come across a time period with no data, even though I am sure my domain received requests at that time. Is this an expected behavior?`}</h3>\n    <p>{`Yes. The time period for which you pull or receive logs is based on our processing time, not the time the requests passed through our network. Empty responses do not mean there were no requests during that time period, just that we did not process any logs for your domain during that time.`}</p>\n    <h3 {...{\n      \"id\": \"can-i-receive-logs-in-a-format-other-than-json\"\n    }}>{`Can I receive logs in a format other than JSON?`}</h3>\n    <p>{`Not at this time. Talk to your account manager or Cloudflare Support if you are interested in other formats and we will consider them for the future.`}</p>\n    <h2 {...{\n      \"id\": \"logpush-faq\"\n    }}>{`Logpush FAQ`}</h2>\n    <h3 {...{\n      \"id\": \"what-happens-if-my-cloud-storage-destination-is-temporarily-unavailable\"\n    }}>{`What happens if my cloud storage destination is temporarily unavailable?`}</h3>\n    <p><strong parentName=\"p\">{`Logpush`}</strong>{` is designed to retry in case of errors. If your destination is temporarily unavailable, Logpush will make the best effort to retry. If Cloudflare persistently receives errors from your destination, Logpush will eventually drop logs. If the errors continue for a prolonged period of time, Logpush will assume that the destination is permanently unavailable and disable your push job. You can always re-enable the job later.`}</p>\n    <h3 {...{\n      \"id\": \"can-i-adjust-how-often-logs-are-pushed\"\n    }}>{`Can I adjust how often logs are pushed?`}</h3>\n    <p>{`No. Cloudflare pushes logs in batches as soon as possible.`}</p>\n    <h3 {...{\n      \"id\": \"my-job-was-accidentally-turned-off-and-i-did-not-receive-my-logs-for-a-certain-time-period-can-they-still-be-pushed-to-me\"\n    }}>{`My job was accidentally turned off, and I did not receive my logs for a certain time period. Can they still be pushed to me?`}</h3>\n    <p>{`No. `}<strong parentName=\"p\">{`Logpush`}</strong>{` only pushes the logs once as they become available and is unable to backfill. However, the logs are stored for at least 72 hours and can be downloaded using the `}<strong parentName=\"p\">{`Logpull API`}</strong>{`.`}</p>\n    <h3 {...{\n      \"id\": \"why-am-i-receiving-a-validating-destination-error-while-setting-up-a-splunk-job\"\n    }}>{`Why am I receiving a validating destination error while setting up a Splunk job?`}</h3>\n    <p>{`You could be seeing this error for multiple reasons:`}</p>\n    <ul>\n      <li parentName=\"ul\">{`The Splunk endpoint URL is not correct. Cloudflare only supports Splunk HEC raw endpoint over HTTPS.`}</li>\n      <li parentName=\"ul\">{`The Splunk authentication token is not correct. Be sure to URL-encode the token. For example, use `}<inlineCode parentName=\"li\">{`%20`}</inlineCode>{` for a space.`}</li>\n      <li parentName=\"ul\">{`The certificate for Splunk Server is not properly configured. Certificates generated by Splunk/third-party certificates should have the `}<strong parentName=\"li\">{`Common Name`}</strong>{` field in the certificate match the Splunk server’s domain name. Otherwise you may see errors like: `}<inlineCode parentName=\"li\">{`x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.`}</inlineCode></li>\n    </ul>\n    <h3 {...{\n      \"id\": \"what-is-the-insecure-skip-verify-parameter-in-splunk-jobs\"\n    }}>{`What is the insecure-skip-verify parameter in Splunk jobs?`}</h3>\n    <p>{`This flag, if set to `}<inlineCode parentName=\"p\">{`true`}</inlineCode>{`, makes an insecure connection to Splunk. Setting this value to `}<inlineCode parentName=\"p\">{`true`}</inlineCode>{` is equivalent to using the `}<inlineCode parentName=\"p\">{`-k`}</inlineCode>{` option with `}<inlineCode parentName=\"p\">{`curl`}</inlineCode>{` as shown in Splunk examples and is `}<strong parentName=\"p\">{`not`}</strong>{` recommended. Cloudflare highly recommends setting this flag to `}<inlineCode parentName=\"p\">{`false`}</inlineCode>{` when using the `}<inlineCode parentName=\"p\">{`insecure-skip-verify`}</inlineCode>{` parameter.`}</p>\n    <h3 {...{\n      \"id\": \"why-do-we-have-the-insecure-skip-verify-parameter-in-splunk-jobs-if-it-is-not-recommended\"\n    }}>{`Why do we have the insecure-skip-verify parameter in Splunk jobs, if it is not recommended?`}</h3>\n    <p>{`Certificates generated by Splunk/third-party certificates should have the `}<strong parentName=\"p\">{`Common Name`}</strong>{` field in the certificate match the Splunk server’s domain name. Otherwise you may see errors like: `}<inlineCode parentName=\"p\">{`x509: certificate is valid for SplunkServerDefaultCert, not <YOUR_INSTANCE>.splunkcloud.com.`}</inlineCode>{` This happens especially with the default certificates generated by Splunk on startup. Pushes will never succeed unless the certificates are fixed.`}</p>\n    <p>{`The proper way to resolve the issue is to fix the certificates. This flag is only here for those rare scenarios when it is not possible to have access or permissions to fix the certificates, like with the Splunk cloud instances, which do not allow changing Splunk server configurations.`}</p>\n    <h3 {...{\n      \"id\": \"how-can-i-verify-that-my-splunk-hec-is-working-correctly-before-setting-up-a-job\"\n    }}>{`How can I verify that my Splunk HEC is working correctly before setting up a job?`}</h3>\n    <p>{`Ensure that you can publish events to your Splunk instance through `}<inlineCode parentName=\"p\">{`curl`}</inlineCode>{` without the `}<inlineCode parentName=\"p\">{`-k`}</inlineCode>{` flag and with the `}<inlineCode parentName=\"p\">{`insecure-skip-verify`}</inlineCode>{` parameter set to `}<inlineCode parentName=\"p\">{`false`}</inlineCode>{`, as in the following example:`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-bash\"\n      }}>{`curl  \"https://<SPLUNK_ENDPOINT_URL>?channel=<SPLUNK_CHANNEL_ID>&insecure-skip-verify=<INSECURE_SKIP_VERIFY>&sourcetype=<SOURCE_TYPE>\" \\\\\n   -H \"Authorization: Splunk <SPLUNK_AUTH_TOKEN>\" \\\\\n   -d '{\"BotScore\":99,\"BotScoreSrc\":\"Machine Learning\",\"CacheCacheStatus\":\"miss\",\"CacheResponseBytes\":2478}'\n{\"text\":\"Success\",\"code\":0}\n`}</code></pre>\n    <h3 {...{\n      \"id\": \"can-i-use-any-hec-network-port-in-the-splunk-destination-conf\"\n    }}>{`Can I use any HEC network port in the Splunk destination conf?`}</h3>\n    <p>{`No. Cloudflare expects the HEC network port to be configured to `}<inlineCode parentName=\"p\">{`:443`}</inlineCode>{` or `}<inlineCode parentName=\"p\">{`:8088`}</inlineCode>{`.`}</p>\n    <h3 {...{\n      \"id\": \"does-logpush-integrate-with-the-cloudflare-splunk-app\"\n    }}>{`Does Logpush integrate with the Cloudflare Splunk App?`}</h3>\n    <p>{`Yes. See `}<a parentName=\"p\" {...{\n        \"href\": \"https://splunkbase.splunk.com/app/4501/\"\n      }}>{`Cloudflare App for Splunk`}</a>{` for more information. As long as you ingest logs using the `}<inlineCode parentName=\"p\">{`cloudflare:json`}</inlineCode>{` source type, you can use the Cloudflare Splunk App.`}</p>\n    <h2 {...{\n      \"id\": \"logpull-api-faq\"\n    }}>{`Logpull API FAQ`}</h2>\n    <h3 {...{\n      \"id\": \"how-long-are-logs-retained\"\n    }}>{`How long are logs retained?`}</h3>\n    <p>{`Cloudflare makes logs available for at least three days and up to seven days. If you need your logs for a longer time period, download and store them locally.`}</p>\n    <h3 {...{\n      \"id\": \"i-am-asking-for-logs-for-the-time-window-of-1610-1613-however-the-timestamps-in-the-logs-show-requests-that-are-before-this-time-period-why-does-that-happen\"\n    }}>{`I am asking for logs for the time window of 16:10-16:13. However, the timestamps in the logs show requests that are before this time period. Why does that happen?`}</h3>\n    <p>{`When you make a call for the time period of 16:10-16:13, you are actually asking for the logs that were received and processed by our system during that time (hence the endpoint name, `}<inlineCode parentName=\"p\">{`logs/received`}</inlineCode>{`). The received time is the time the logs are written to disk. There is some delay between the time the request hits the Cloudflare edge and the time it is received and processed. The `}<strong parentName=\"p\">{`request time`}</strong>{` is what you see in the log itself: `}<strong parentName=\"p\">{`EdgeStartTimestamp`}</strong>{` and `}<strong parentName=\"p\">{`EdgeEndTimestamp`}</strong>{` tell you when the edge started and stopped processing the request.`}</p>\n    <p>{`The advantage of basing the responses on the `}<strong parentName=\"p\">{`time received`}</strong>{` rather than the request or edge time is not needing to worry about late-arriving logs. As long as you are calling our API for continuous time segments, you will always get all of your logs without making duplicate calls. If we based the response on request time, you could never be sure that all the logs for that request time had been processed.`}</p>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}
{"data":{"mdx":{"id":"70b47aed-e0ed-5310-9497-c6e72daacb55","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"pcx-content-type\": \"interim\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar Aside = makeShortcode(\"Aside\");\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"export-graphql-data-to-csv\"\n  }, \"Export GraphQL data to CSV\"), mdx(\"p\", null, \"This tutorial shows how to create a Python script to query the GraphQL API for\\nNetwork Analytics data and convert the response to comma-separated values (CSV).\\nProduced CSV could be easily ingested by tools like \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.splunk.com\"\n  }, \"Splunk\"), \" for further\\nvisualization and usage.\"), mdx(\"p\", null, \"Therefore, this example queries the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ipFlows1mAttacksGroups\"), \" \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/graphql-api/features/data-sets\"\n  }, \"data set\"), \",\\nwhich containes minutely aggregates of Network Analytics attack activity.\"), mdx(Aside, {\n    type: \"warning\",\n    mdxType: \"Aside\"\n  }, mdx(\"p\", null, \"This tutorial uses Network Analytics v1 (NAv1) nodes. These nodes are planned to\\nbe deprecated on March 31, 2022. For more information on migrating from Network\\nAnalytics v1 to Network Analytics v2, refer to the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/graphql-api/migration-guides/network-analytics-v2\"\n  }, \"migration guide\"), \".\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"prerequisites\"\n  }, \"Prerequisites\"), mdx(\"p\", null, \"This tutorial assumes that you already have a Cloudflare API token for authentication to the Analytics GraphQL API (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Account Analytics: read\"), \" permission). If you do not already have one, refer to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/graphql-api/getting-started/authentication/api-token-auth\"\n  }, \"Configure an Analytics API token\"), \".\"), mdx(\"p\", null, \"The scripts also require Python 3.6 or higher.\"), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"set-up-a-script-with-authentication\"\n  }, \"Set up a script with authentication\"), mdx(\"p\", null, \"The first step is to set up the script and define the variables for further\\nauthentication with the GraphQL API using a Cloudflare API token. The script\\nalso provides variables to set the range of data to export.\"), mdx(\"p\", null, \"This example queries for a seven-day period that ended yesterday.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"---\\nheader: Set up script and authentication\\n---\\n#!/usr/bin/env python3\\n\\nimport pandas as pd\\nfrom datetime import datetime, timedelta\\nimport requests\\n\\n# the endpoint of GraphQL API\\nurl = 'https://api.cloudflare.com/client/v4/graphql/'\\n\\n# Customize these variables.\\nfile_dir = ''  # Must include trailing slash. If left blank,\\n# csv will be created in the current directory.\\napi_token = '[your API token here]'\\napi_account = '[your account ID here]'\\n# Set most recent day as yesterday by default.\\noffset_days = 1\\n# How many days worth of data do we want? By default, 7.\\nhistorical_days = 7\\n\")), mdx(\"h2\", {\n    \"id\": \"calculate-the-date-n-days-ago\"\n  }, \"Calculate the date \", mdx(\"em\", {\n    parentName: \"h2\"\n  }, \"n\"), \" days ago\"), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_date()\"), \" function takes a number of days (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"num_days\"), \"), subtracts\\nthat value from today's date, and returns the date \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"num_days\"), \" ago.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"---\\nheader: Calculates the datetime num_days ago and returns it in ISO format\\n---\\ndef get_date(num_days):\\n    today = datetime.utcnow().date()\\n    return today - timedelta(days=num_days)\\n\")), mdx(\"p\", null, \"The script uses \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_date()\"), \" with the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"offset_days\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"historical_days\"), \"\\nvariables to calculate the appropriate date range (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"min_date\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"max_date\"), \")\\nwhen it queries the GraphQL API.\"), mdx(\"h2\", {\n    \"id\": \"query-the-graphql-api\"\n  }, \"Query the GraphQL API\"), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"get_cf_graphql()\"), \" function assembles and sends a request to the GraphQL\\nAPI. The headers will include the data for authentication.\"), mdx(\"p\", null, \"The payload contains the GraphQL query. In this query, we would like to get a\\nlist of the next fields for a given account and time range:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"attack ID\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"attack type\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"start time\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"end time\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mitigation type\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"avg, max rate of packets per second\")), mdx(\"p\", null, \"To get started with GraphQL queries, please see \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/graphql-api/getting-started/querying-basics\"\n  }, mdx(\"em\", {\n    parentName: \"a\"\n  }, \"Querying basics\")), \".\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"---\\nheader: Query the Network Analytics GraphQL API\\n---\\ndef get_cf_graphql(start_date, end_date):\\n    headers = {\\n        'Content-Type': 'application/json',\\n        'Authorization': f'Bearer {api_token}'\\n    }\\n    # The GQL query we would like to use:\\n    payload = f'''{{\\\"query\\\":\\n      \\\"query ipFlowEventLog($accountTag: string) {{\\n        viewer {{\\n          accounts(\\n            filter: {{ accountTag: $accountTag }}\\n          ) {{\\n            ipFlows1mAttacksGroups(\\n              filter: $filter\\n              limit: 10000\\n              orderBy: [min_datetimeMinute_ASC]\\n            ) {{\\n              dimensions {{\\n                attackId\\n                attackDestinationIP\\n                attackMitigationType\\n                attackType\\n              }}\\n              avg {{\\n                packetsPerSecond\\n              }}\\n              min {{\\n                datetimeMinute\\n              }}\\n              max {{\\n                datetimeMinute\\n                packetsPerSecond\\n              }}\\n            }}\\n          }}\\n        }}\\n      }}\\\",\\n      \\\"variables\\\": {{\\n        \\\"accountTag\\\": \\\"{api_account}\\\",\\n        \\\"filter\\\": {{\\n          \\\"AND\\\":[\\n            {{\\n              \\\"date_geq\\\": \\\"{start_date}\\\"\\n            }},\\n            {{\\n              \\\"date_leq\\\": \\\"{end_date}\\\"\\n            }}\\n          ]\\n        }}\\n      }}\\n    }}'''\\n\\n    r = requests.post(url, data=payload.replace('\\\\n', ''), headers=headers)\\n    return r\\n\")), mdx(\"h3\", {\n    \"id\": \"additional-notes\"\n  }, \"Additional notes\"), mdx(\"p\", null, \"The braces used in the GraphQL query are doubled to escape them in\\nPython's f-string.\"), mdx(\"p\", null, \"GraphQL also requires a query to be a single-line text,\\ntherefore we should remove all newline symbols before sending a query.\"), mdx(\"h2\", {\n    \"id\": \"convert-the-data-to-csv\"\n  }, \"Convert the data to CSV\"), mdx(\"p\", null, \"Use a tool such as the open-source \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://pandas.pydata.org/pandas-docs/stable/index.html\"\n  }, \"pandas\"), \" library (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pd\"), \") to convert a\\nresponse from the GraphQL API (JSON) to CSV.\"), mdx(\"p\", null, \"In this example, the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"convert_to_csv()\"), \" function does a bit of JSON processing\\nbefore conversion\\u2014normalizing the data, selecting only the desired data, and\\nrenaming the columns so that they are user-friendly. The function also checks\\nwhether the API responded successfully or we got an error.\"), mdx(\"p\", null, \"The result is output to file in the directory specified by \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"file_dir\"), \".\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"---\\nheader: Convert the data to CSV\\n---\\ndef convert_to_csv(raw_data, start_date, end_date):\\n    data = pd.read_json(raw_data, dtype=False)['data']\\n    errors = pd.read_json(raw_data, dtype=False)['errors']\\n\\n    # Check if we got any errors\\n    if errors.notna().any() or not 'viewer' in data or not 'accounts' in data['viewer']:\\n        print('Failed to retrieve data: GraphQL API responded with error:')\\n        print(raw_data)\\n        return\\n\\n    # Flatten nested JSON data first\\n    network_analytics_normalized = pd.json_normalize(data['viewer']['accounts'], 'ipFlows1mAttacksGroups')\\n\\n    if len(network_analytics_normalized) == 0:\\n        print('We got empty response')\\n        return\\n\\n    network_analytics_abridged = network_analytics_normalized[[\\n      'dimensions.attackId',\\n      'min.datetimeMinute',\\n      'max.datetimeMinute',\\n      'dimensions.attackMitigationType',\\n      'dimensions.attackType',\\n      'dimensions.attackDestinationIP',\\n      'max.packetsPerSecond',\\n      'avg.packetsPerSecond']]\\n    # Rename the columns to get friendly names\\n    network_analytics_abridged.columns = [\\n      'Attack ID',\\n      'Started at',\\n      'Ended at',\\n      'Action taken',\\n      'Attack type',\\n      'Destination IP',\\n      'Max packets/second',\\n      'Avg packets/second']\\n    file = \\\"{}network-analytics-{}-{}.csv\\\".format(file_dir, start_date, end_date)\\n    network_analytics_abridged.to_csv(file)\\n    print(\\\"Successfully exported to {}\\\".format(file))\\n\")), mdx(\"h2\", {\n    \"id\": \"the-final-script\"\n  }, \"The final script\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"---\\nheader: Get Cloudflare Network Analytics via GraphQL API in CSV format\\n---\\n#!/usr/bin/env python3\\n\\nimport pandas as pd\\nfrom datetime import datetime, timedelta\\nimport requests\\n\\n# the endpoint of GraphQL API\\nurl = 'https://api.cloudflare.com/client/v4/graphql/'\\n\\n# Customize these variables.\\nfile_dir = ''  # Must include trailing slash. If left blank,\\n# csv will be created in the current directory.\\napi_token = '[your API token here]'\\napi_account = '[your account ID here]'\\n# Set most recent day as yesterday by default.\\noffset_days = 1\\n# How many days worth of data do we want? By default, 7.\\nhistorical_days = 7\\n\\ndef get_date(num_days):\\n    today = datetime.utcnow().date()\\n    return today - timedelta(days=num_days)\\n\\ndef get_cf_graphql(start_date, end_date):\\n    headers = {\\n        'Content-Type': 'application/json',\\n        'Authorization': f'Bearer {api_token}'\\n    }\\n    # The GQL query we would like to use:\\n    payload = f'''{{\\\"query\\\":\\n      \\\"query ipFlowEventLog($accountTag: string) {{\\n        viewer {{\\n          accounts(\\n            filter: {{ accountTag: $accountTag }}\\n          ) {{\\n            ipFlows1mAttacksGroups(\\n              filter: $filter\\n              limit: 10000\\n              orderBy: [min_datetimeMinute_ASC]\\n            ) {{\\n              dimensions {{\\n                attackId\\n                attackDestinationIP\\n                attackMitigationType\\n                attackType\\n              }}\\n              avg {{\\n                packetsPerSecond\\n              }}\\n              min {{\\n                datetimeMinute\\n              }}\\n              max {{\\n                datetimeMinute\\n                packetsPerSecond\\n              }}\\n            }}\\n          }}\\n        }}\\n      }}\\\",\\n      \\\"variables\\\": {{\\n        \\\"accountTag\\\": \\\"{api_account}\\\",\\n        \\\"filter\\\": {{\\n          \\\"AND\\\":[\\n            {{\\n              \\\"date_geq\\\": \\\"{start_date}\\\"\\n            }},\\n            {{\\n              \\\"date_leq\\\": \\\"{end_date}\\\"\\n            }}\\n          ]\\n        }}\\n      }}\\n    }}'''\\n\\n    r = requests.post(url, data=payload.replace('\\\\n', ''), headers=headers)\\n    return r\\n\\ndef convert_to_csv(raw_data, start_date, end_date):\\n    data = pd.read_json(raw_data, dtype=False)['data']\\n    errors = pd.read_json(raw_data, dtype=False)['errors']\\n\\n    # Check if we got any errors\\n    if errors.notna().any() or not 'viewer' in data or not 'accounts' in data['viewer']:\\n        print('Failed to retrieve data: GraphQL API responded with error:')\\n        print(raw_data)\\n        return\\n\\n    # Flatten nested JSON data first\\n    network_analytics_normalized = pd.json_normalize(data['viewer']['accounts'], 'ipFlows1mAttacksGroups')\\n\\n    if len(network_analytics_normalized) == 0:\\n        print('We got empty response')\\n        return\\n\\n    network_analytics_abridged = network_analytics_normalized[[\\n      'dimensions.attackId',\\n      'min.datetimeMinute',\\n      'max.datetimeMinute',\\n      'dimensions.attackMitigationType',\\n      'dimensions.attackType',\\n      'dimensions.attackDestinationIP',\\n      'max.packetsPerSecond',\\n      'avg.packetsPerSecond']]\\n    # Rename the columns to get friendly names\\n    network_analytics_abridged.columns = [\\n      'Attack ID',\\n      'Started at',\\n      'Ended at',\\n      'Action taken',\\n      'Attack type',\\n      'Destination IP',\\n      'Max packets/second',\\n      'Avg packets/second']\\n    file = \\\"{}network-analytics-{}-{}.csv\\\".format(file_dir, start_date, end_date)\\n    network_analytics_abridged.to_csv(file)\\n    print(\\\"Successfully exported to {}\\\".format(file))\\n \\nstart_date = get_date(offset_days)\\nend_date = get_date(historical_days)\\n \\nreq = get_cf_graphql(start_date, end_date)\\nif req.status_code == 200:\\n  convert_to_csv(req.text, start_date, end_date)\\nelse:\\n  print(\\\"Failed to retrieve data: GraphQL API responded with {} status code\\\".format(req.status_code))\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"demo":null,"difficulty":null,"summary":null,"tags":null,"title":"","type":null,"updated":null}}},"pageContext":{"id":"70b47aed-e0ed-5310-9497-c6e72daacb55","fields":{"slug":"/graphql-api/tutorials/export-graphql-to-csv"},"frontmatter":{"title":"","type":null,"order":null,"hidden":null,"hideChildren":null,"breadcrumbs":null},"headings":[{"value":"Export GraphQL data to CSV","depth":1}],"tableOfContents":{"items":[{"url":"#export-graphql-data-to-csv","title":"Export GraphQL data to CSV","items":[{"url":"#prerequisites","title":"Prerequisites"},{"url":"#set-up-a-script-with-authentication","title":"Set up a script with authentication"},{"url":"#calculate-the-date-n-days-ago","title":"Calculate the date n days ago"},{"url":"#query-the-graphql-api","title":"Query the GraphQL API","items":[{"url":"#additional-notes","title":"Additional notes"}]},{"url":"#convert-the-data-to-csv","title":"Convert the data to CSV"},{"url":"#the-final-script","title":"The final script"}]}]},"parent":{"modifiedTime":"2021-10-26","relativePath":"graphql-api/tutorials/export-graphql-to-csv/index.md"}}}